# GPU è®­ç»ƒæŒ‡å—

## âœ… å¥½æ¶ˆæ¯ï¼šä»£ç å·²è‡ªåŠ¨æ”¯æŒ GPUï¼

DQN agent å·²ç»å†…ç½®äº† GPU æ”¯æŒï¼Œ**ä¼šè‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨ GPU**ï¼ˆå¦‚æœå¯ç”¨ï¼‰ã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. æ£€æŸ¥ GPU æ˜¯å¦å¯ç”¨

è¿è¡Œä»¥ä¸‹å‘½ä»¤æ£€æŸ¥ï¼š

```python
import torch
print(f"CUDA available: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"GPU device: {torch.cuda.get_device_name(0)}")
    print(f"CUDA version: {torch.version.cuda}")
```

### 2. è‡ªåŠ¨ä½¿ç”¨ GPU

**æ— éœ€ä»»ä½•é¢å¤–é…ç½®ï¼** ä»£ç ä¼šè‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨ GPUï¼š

```python
from agent_Qlearning import DQNAgent

# åˆ›å»º agentï¼ˆä¼šè‡ªåŠ¨ä½¿ç”¨ GPUï¼Œå¦‚æœå¯ç”¨ï¼‰
agent = DQNAgent(
    special_pos=None,
    auto_detect_special=True,
    learning_rate=0.001
)

# æŸ¥çœ‹ä½¿ç”¨çš„è®¾å¤‡
print(f"Using device: {agent.device}")
# è¾“å‡º: Using device: cuda æˆ– Using device: cpu
```

### 3. è®­ç»ƒæ—¶æŸ¥çœ‹è®¾å¤‡ä¿¡æ¯

è¿è¡Œè®­ç»ƒè„šæœ¬æ—¶ï¼Œä¼šè‡ªåŠ¨æ˜¾ç¤ºä½¿ç”¨çš„è®¾å¤‡ï¼š

```bash
python train_dqn.py --episodes 10000
```

è¾“å‡ºç¤ºä¾‹ï¼š
```
============================================================
DQN Agent Training for 2048 Game
============================================================
...
Training parameters:
  Device: cuda  # æˆ– cpu
============================================================
```

## ğŸ“¦ å®‰è£… CUDA ç‰ˆæœ¬çš„ PyTorch

### å¦‚æœè¿˜æ²¡æœ‰å®‰è£… PyTorch

**CPU ç‰ˆæœ¬ï¼ˆé»˜è®¤ï¼‰ï¼š**
```bash
pip install torch
```

**GPU ç‰ˆæœ¬ï¼ˆæ¨èï¼Œå¦‚æœ NVIDIA GPUï¼‰ï¼š**

1. **æ£€æŸ¥ CUDA ç‰ˆæœ¬ï¼š**
   ```bash
   nvidia-smi
   ```
   æŸ¥çœ‹ CUDA Versionï¼ˆä¾‹å¦‚ï¼š12.1ï¼‰

2. **å®‰è£…å¯¹åº”ç‰ˆæœ¬çš„ PyTorchï¼š**

   **CUDA 11.8ï¼š**
   ```bash
   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
   ```

   **CUDA 12.1ï¼š**
   ```bash
   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
   ```

   **æœ€æ–°ç¨³å®šç‰ˆï¼ˆæ¨èï¼‰ï¼š**
   ```bash
   pip install torch torchvision torchaudio
   ```

3. **éªŒè¯å®‰è£…ï¼š**
   ```python
   import torch
   print(torch.cuda.is_available())  # åº”è¯¥è¾“å‡º True
   print(torch.cuda.get_device_name(0))  # æ˜¾ç¤º GPU åç§°
   ```

## ğŸ¯ å¼ºåˆ¶ä½¿ç”¨ CPUï¼ˆå¦‚æœéœ€è¦ï¼‰

å¦‚æœä½ æƒ³å¼ºåˆ¶ä½¿ç”¨ CPUï¼ˆä¾‹å¦‚ç”¨äºè°ƒè¯•ï¼‰ï¼š

```python
import torch
from agent_Qlearning import DQNAgent

# å¼ºåˆ¶ä½¿ç”¨ CPU
agent = DQNAgent(
    special_pos=None,
    device=torch.device("cpu"),  # å¼ºåˆ¶ä½¿ç”¨ CPU
    learning_rate=0.001
)
```

## ğŸ¯ å¼ºåˆ¶ä½¿ç”¨ç‰¹å®š GPU

å¦‚æœä½ æœ‰å¤šä¸ª GPUï¼Œå¯ä»¥æŒ‡å®šä½¿ç”¨å“ªä¸ªï¼š

```python
import torch
from agent_Qlearning import DQNAgent

# ä½¿ç”¨ç¬¬ä¸€ä¸ª GPU
agent = DQNAgent(
    special_pos=None,
    device=torch.device("cuda:0"),  # ä½¿ç”¨ GPU 0
    learning_rate=0.001
)

# ä½¿ç”¨ç¬¬äºŒä¸ª GPU
agent = DQNAgent(
    special_pos=None,
    device=torch.device("cuda:1"),  # ä½¿ç”¨ GPU 1
    learning_rate=0.001
)
```

## ğŸ“Š GPU vs CPU æ€§èƒ½å¯¹æ¯”

| é¡¹ç›® | CPU | GPU |
|------|-----|-----|
| **è®­ç»ƒé€Ÿåº¦** | åŸºå‡† | **5-20x æ›´å¿«** |
| **æ‰¹æ¬¡å¤§å°** | 32-64 | **64-256** |
| **å†…å­˜ä½¿ç”¨** | è¾ƒä½ | è¾ƒé«˜ |
| **é€‚ç”¨åœºæ™¯** | å°è§„æ¨¡è®­ç»ƒ | **å¤§è§„æ¨¡è®­ç»ƒ** |

### å®é™…æ€§èƒ½æå‡

- **å°è§„æ¨¡è®­ç»ƒï¼ˆ1000 episodesï¼‰**ï¼šGPU å¯èƒ½ä¸æ˜æ˜¾
- **å¤§è§„æ¨¡è®­ç»ƒï¼ˆ10000+ episodesï¼‰**ï¼šGPU å¯ä»¥æ˜¾è‘—åŠ é€Ÿï¼ˆ5-20å€ï¼‰

## ğŸ”§ ä¼˜åŒ– GPU ä½¿ç”¨

### 1. å¢åŠ æ‰¹æ¬¡å¤§å°

GPU å¯ä»¥å¤„ç†æ›´å¤§çš„æ‰¹æ¬¡ï¼š

```python
agent = DQNAgent(
    batch_size=128,  # GPU å¯ä»¥ä½¿ç”¨æ›´å¤§çš„æ‰¹æ¬¡ï¼ˆCPU å»ºè®® 32-64ï¼‰
    memory_size=200000,  # ä¹Ÿå¯ä»¥å¢åŠ ç»éªŒå›æ”¾ç¼“å†²åŒº
)
```

### 2. è°ƒæ•´è®­ç»ƒå‚æ•°

```bash
# GPU è®­ç»ƒå»ºè®®å‚æ•°
python train_dqn.py \
    --episodes 50000 \
    --batch-size 128 \
    --memory-size 200000 \
    --learning-rate 0.001
```

## âš ï¸ å¸¸è§é—®é¢˜

### Q1: ä¸ºä»€ä¹ˆæ˜¾ç¤º "Device: cpu"ï¼Ÿ

**å¯èƒ½åŸå› ï¼š**
1. æ²¡æœ‰å®‰è£… CUDA ç‰ˆæœ¬çš„ PyTorch
2. æ²¡æœ‰ NVIDIA GPU
3. CUDA é©±åŠ¨æœªå®‰è£…æˆ–ç‰ˆæœ¬ä¸åŒ¹é…

**è§£å†³æ–¹æ¡ˆï¼š**
- æ£€æŸ¥ `nvidia-smi` æ˜¯å¦æ­£å¸¸å·¥ä½œ
- å®‰è£… CUDA ç‰ˆæœ¬çš„ PyTorch
- æ£€æŸ¥ CUDA ç‰ˆæœ¬å…¼å®¹æ€§

### Q2: GPU å†…å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ

**è§£å†³æ–¹æ¡ˆï¼š**
```python
# å‡å°‘æ‰¹æ¬¡å¤§å°
agent = DQNAgent(
    batch_size=32,  # ä» 64 å‡å°‘åˆ° 32
    memory_size=50000,  # å‡å°‘ç»éªŒå›æ”¾ç¼“å†²åŒº
)
```

### Q3: å¦‚ä½•æŸ¥çœ‹ GPU ä½¿ç”¨æƒ…å†µï¼Ÿ

**è®­ç»ƒæ—¶ç›‘æ§ GPUï¼š**

```bash
# åœ¨å¦ä¸€ä¸ªç»ˆç«¯çª—å£è¿è¡Œ
watch -n 1 nvidia-smi
```

æˆ–è€…åœ¨ Python ä¸­ï¼š
```python
import torch
print(f"GPU memory allocated: {torch.cuda.memory_allocated(0) / 1024**2:.2f} MB")
print(f"GPU memory reserved: {torch.cuda.memory_reserved(0) / 1024**2:.2f} MB")
```

### Q4: è®­ç»ƒæ—¶ GPU ä½¿ç”¨ç‡å¾ˆä½ï¼Ÿ

**å¯èƒ½åŸå› ï¼š**
- æ‰¹æ¬¡å¤§å°å¤ªå°
- ç½‘ç»œå¤ªå°
- æ•°æ®é¢„å¤„ç†æ˜¯ç“¶é¢ˆ

**è§£å†³æ–¹æ¡ˆï¼š**
- å¢åŠ  `batch_size`ï¼ˆ64 â†’ 128 æˆ–æ›´å¤§ï¼‰
- ç¡®ä¿æ•°æ®åœ¨ GPU ä¸Šï¼ˆä»£ç å·²è‡ªåŠ¨å¤„ç†ï¼‰

## ğŸ“ å®Œæ•´ç¤ºä¾‹

### ä½¿ç”¨ GPU è®­ç»ƒ

```python
from agent_Qlearning import DQNAgent, train_dqn_agent
import torch

# æ£€æŸ¥ GPU
if torch.cuda.is_available():
    print(f"âœ… Using GPU: {torch.cuda.get_device_name(0)}")
else:
    print("âš ï¸  GPU not available, using CPU")

# åˆ›å»º agentï¼ˆè‡ªåŠ¨ä½¿ç”¨ GPUï¼‰
agent = DQNAgent(
    special_pos=None,
    auto_detect_special=True,
    learning_rate=0.001,
    batch_size=128,  # GPU å¯ä»¥ä½¿ç”¨æ›´å¤§çš„æ‰¹æ¬¡
    memory_size=200000
)

# å¼€å§‹è®­ç»ƒ
train_dqn_agent(
    agent,
    num_episodes=10000,
    save_freq=1000,
    save_path="dqn_2048_model.pth"
)
```

### ä½¿ç”¨è®­ç»ƒè„šæœ¬

```bash
# è‡ªåŠ¨ä½¿ç”¨ GPUï¼ˆå¦‚æœå¯ç”¨ï¼‰
python train_dqn.py --episodes 10000 --batch-size 128
```

## ğŸ‰ æ€»ç»“

1. **ä»£ç å·²è‡ªåŠ¨æ”¯æŒ GPU** - æ— éœ€é¢å¤–é…ç½®
2. **è‡ªåŠ¨æ£€æµ‹** - å¦‚æœæœ‰ GPU ä¼šè‡ªåŠ¨ä½¿ç”¨
3. **æ€§èƒ½æå‡** - GPU è®­ç»ƒé€Ÿåº¦å¯æå‡ 5-20 å€
4. **ç®€å•ä½¿ç”¨** - ç›´æ¥è¿è¡Œè®­ç»ƒè„šæœ¬å³å¯

**å¼€å§‹è®­ç»ƒï¼š**
```bash
python train_dqn.py --episodes 10000
```

ä»£ç ä¼šè‡ªåŠ¨ä½¿ç”¨ GPUï¼ˆå¦‚æœå¯ç”¨ï¼‰ï¼ğŸš€



