# DQN Agent è®­ç»ƒæŒ‡å—

## ğŸ“‹ å¿«é€Ÿå¼€å§‹

### æ–¹æ³• 1ï¼šä½¿ç”¨è®­ç»ƒè„šæœ¬ï¼ˆæ¨èï¼‰

```bash
# åŸºç¡€è®­ç»ƒï¼ˆ10000 episodesï¼‰
python train_dqn.py

# è‡ªå®šä¹‰å‚æ•°è®­ç»ƒ
python train_dqn.py --episodes 20000 --save-freq 2000 --learning-rate 0.0005
```

### æ–¹æ³• 2ï¼šåœ¨ Python ä¸­ç›´æ¥è®­ç»ƒ

```python
from agent_Qlearning import DQNAgent, train_dqn_agent

# åˆ›å»º agent
agent = DQNAgent(
    special_pos=None,  # è‡ªåŠ¨æ£€æµ‹ç‰¹æ®Šæ ¼ä½ç½®
    auto_detect_special=True,
    learning_rate=0.001,
    gamma=0.99,
    epsilon_start=1.0,
    epsilon_end=0.01,
    epsilon_decay=0.995
)

# å¼€å§‹è®­ç»ƒ
train_dqn_agent(agent, num_episodes=10000, save_path="dqn_2048_model.pth")
```

---

## ğŸ¯ è®­ç»ƒå‚æ•°è¯´æ˜

### åŸºç¡€å‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ | å»ºè®®èŒƒå›´ |
|------|--------|------|----------|
| `num_episodes` | 10000 | è®­ç»ƒè½®æ•° | 5000-50000 |
| `save_freq` | 1000 | ä¿å­˜é¢‘ç‡ | 500-2000 |
| `learning_rate` | 0.001 | å­¦ä¹ ç‡ | 0.0001-0.01 |
| `gamma` | 0.99 | æŠ˜æ‰£å› å­ | 0.95-0.99 |
| `epsilon_start` | 1.0 | åˆå§‹æ¢ç´¢ç‡ | 1.0 |
| `epsilon_end` | 0.01 | æœ€ç»ˆæ¢ç´¢ç‡ | 0.01-0.1 |
| `epsilon_decay` | 0.995 | æ¢ç´¢ç‡è¡°å‡ | 0.99-0.999 |
| `batch_size` | 64 | æ‰¹æ¬¡å¤§å° | 32-128 |
| `memory_size` | 100000 | ç»éªŒå›æ”¾ç¼“å†²åŒºå¤§å° | 50000-200000 |
| `target_update_freq` | 1000 | ç›®æ ‡ç½‘ç»œæ›´æ–°é¢‘ç‡ | 500-2000 |

### ç‰¹æ®Šæ ¼ä½ç½®

- **è‡ªåŠ¨æ£€æµ‹**ï¼ˆæ¨èï¼‰ï¼š`special_pos=None, auto_detect_special=True`
- **æ‰‹åŠ¨æŒ‡å®š**ï¼š`special_pos=(1, 1), auto_detect_special=False`

---

## ğŸ“Š è®­ç»ƒè¿‡ç¨‹ç›‘æ§

è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šæ¯ 100 episodes æ‰“å°ä¸€æ¬¡ç»Ÿè®¡ä¿¡æ¯ï¼š

```
Episode 100/10000 | Avg Reward: -1234.56 | Avg Length: 45.23 | Epsilon: 0.951
```

### å…³é”®æŒ‡æ ‡

- **Avg Reward**ï¼šå¹³å‡å¥–åŠ±ï¼ˆåº”è¯¥é€æ¸å¢åŠ ï¼‰
- **Avg Length**ï¼šå¹³å‡æ¸¸æˆé•¿åº¦ï¼ˆåº”è¯¥é€æ¸å¢åŠ ï¼‰
- **Epsilon**ï¼šå½“å‰æ¢ç´¢ç‡ï¼ˆåº”è¯¥é€æ¸é™ä½ï¼‰

### æ­£å¸¸è®­ç»ƒè¡¨ç°

- âœ… å¹³å‡å¥–åŠ±é€æ¸å¢åŠ ï¼ˆä»è´Ÿæ•°å˜ä¸ºæ­£æ•°ï¼‰
- âœ… å¹³å‡æ¸¸æˆé•¿åº¦é€æ¸å¢åŠ 
- âœ… Epsilon é€æ¸é™ä½ï¼ˆæ¢ç´¢å‡å°‘ï¼Œåˆ©ç”¨å¢åŠ ï¼‰

### å¼‚å¸¸æƒ…å†µ

- âŒ å¹³å‡å¥–åŠ±ä¸€ç›´ä¸ºè´Ÿæ•°ä¸”ä¸å¢åŠ  â†’ é™ä½å­¦ä¹ ç‡æˆ–è°ƒæ•´å¥–åŠ±å‡½æ•°
- âŒ å¹³å‡é•¿åº¦å¾ˆçŸ­ â†’ æ£€æŸ¥å¥–åŠ±å‡½æ•°ï¼Œå¯èƒ½éœ€è¦å¢åŠ ç©ºæ ¼å¥–åŠ±
- âŒ è®­ç»ƒä¸ç¨³å®šï¼ˆå¥–åŠ±æ³¢åŠ¨å¤§ï¼‰ â†’ å¢åŠ ç›®æ ‡ç½‘ç»œæ›´æ–°é¢‘ç‡

---

## ğŸ”§ è®­ç»ƒé…ç½®å»ºè®®

### å¿«é€Ÿæµ‹è¯•ï¼ˆéªŒè¯ä»£ç ï¼‰

```bash
python train_dqn.py --episodes 1000 --save-freq 500
```

### åŸºç¡€è®­ç»ƒï¼ˆæ¨èå¼€å§‹ï¼‰

```bash
python train_dqn.py --episodes 10000 --save-freq 1000
```

### æ·±åº¦è®­ç»ƒï¼ˆè¿½æ±‚æ›´å¥½æ€§èƒ½ï¼‰

```bash
python train_dqn.py \
    --episodes 50000 \
    --save-freq 2000 \
    --learning-rate 0.0005 \
    --epsilon-decay 0.998 \
    --batch-size 128
```

### ç»§ç»­è®­ç»ƒï¼ˆä»å·²æœ‰æ¨¡å‹ç»§ç»­ï¼‰

```bash
python train_dqn.py \
    --episodes 20000 \
    --load-path dqn_2048_model.pth \
    --save-path dqn_2048_model_v2.pth
```

---

## ğŸ’¡ è®­ç»ƒæŠ€å·§

### 1. æ¸è¿›å¼è®­ç»ƒ

```bash
# ç¬¬ä¸€é˜¶æ®µï¼šå¿«é€Ÿæ¢ç´¢ï¼ˆé«˜æ¢ç´¢ç‡ï¼‰
python train_dqn.py --episodes 5000 --epsilon-decay 0.99

# ç¬¬äºŒé˜¶æ®µï¼šç²¾ç»†è°ƒä¼˜ï¼ˆä½æ¢ç´¢ç‡ï¼‰
python train_dqn.py --episodes 20000 --load-path dqn_2048_model.pth --epsilon-start 0.1 --epsilon-decay 0.999
```

### 2. è°ƒæ•´å¥–åŠ±å‡½æ•°

å¦‚æœè®­ç»ƒæ•ˆæœä¸å¥½ï¼Œå¯ä»¥åœ¨ `agent_Qlearning.py` ä¸­è°ƒæ•´ï¼š

```python
# åœ¨ DQNAgent.__init__ ä¸­
self.merge_reward_scale = 10      # åˆå¹¶å¥–åŠ±ç¼©æ”¾
self.large_penalty = -100         # å¤§æ•°å­—è¿›å…¥ç‰¹æ®Šæ ¼æƒ©ç½š
self.small_reward = 10             # å°æ•°å­—è¿›å…¥ç‰¹æ®Šæ ¼å¥–åŠ±
self.terminal_penalty = -1000      # æ¸¸æˆç»“æŸæƒ©ç½š
```

### 3. ä½¿ç”¨ GPU åŠ é€Ÿ

å¦‚æœæœ‰ NVIDIA GPUï¼š

```bash
# å®‰è£… CUDA ç‰ˆæœ¬çš„ PyTorch
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Agent ä¼šè‡ªåŠ¨ä½¿ç”¨ GPUï¼ˆå¦‚æœå¯ç”¨ï¼‰
```

### 4. ç›‘æ§è®­ç»ƒè¿›åº¦

è®­ç»ƒè¿‡ç¨‹ä¸­å¯ä»¥ï¼š
- è§‚å¯Ÿæ§åˆ¶å°è¾“å‡ºçš„ç»Ÿè®¡ä¿¡æ¯
- å®šæœŸæ£€æŸ¥ä¿å­˜çš„æ¨¡å‹æ–‡ä»¶
- åœ¨æ¸¸æˆä¸­æµ‹è¯•å·²è®­ç»ƒçš„æ¨¡å‹

---

## ğŸ“ˆ è®­ç»ƒç¤ºä¾‹

### å®Œæ•´è®­ç»ƒæµç¨‹

```bash
# 1. åˆå§‹è®­ç»ƒï¼ˆ10000 episodesï¼‰
python train_dqn.py --episodes 10000 --save-path dqn_2048_model.pth

# 2. æµ‹è¯•æ¨¡å‹æ€§èƒ½
# åœ¨æ¸¸æˆä¸­åŠ è½½æ¨¡å‹å¹¶æµ‹è¯•

# 3. ç»§ç»­è®­ç»ƒï¼ˆå¦‚æœæ•ˆæœä¸å¤Ÿå¥½ï¼‰
python train_dqn.py \
    --episodes 20000 \
    --load-path dqn_2048_model.pth \
    --save-path dqn_2048_model_v2.pth \
    --learning-rate 0.0005

# 4. æœ€ç»ˆä¼˜åŒ–
python train_dqn.py \
    --episodes 20000 \
    --load-path dqn_2048_model_v2.pth \
    --save-path dqn_2048_model_final.pth \
    --epsilon-start 0.1 \
    --epsilon-decay 0.9995
```

---

## âš ï¸ å¸¸è§é—®é¢˜

### Q1: è®­ç»ƒå¾ˆæ…¢æ€ä¹ˆåŠï¼Ÿ

**è§£å†³æ–¹æ¡ˆï¼š**
- å‡å°‘ `num_episodes`ï¼ˆå…ˆæµ‹è¯• 1000 episodesï¼‰
- å‡å°‘ `memory_size`ï¼ˆå¦‚æœå†…å­˜ä¸è¶³ï¼‰
- å‡å°‘ `batch_size`ï¼ˆå¦‚æœæ˜¾å­˜ä¸è¶³ï¼‰
- ä½¿ç”¨ GPUï¼ˆå¦‚æœæœ‰ï¼‰

### Q2: è®­ç»ƒä¸æ”¶æ•›æ€ä¹ˆåŠï¼Ÿ

**è§£å†³æ–¹æ¡ˆï¼š**
- é™ä½å­¦ä¹ ç‡ï¼ˆ`--learning-rate 0.0005`ï¼‰
- å¢åŠ ç›®æ ‡ç½‘ç»œæ›´æ–°é¢‘ç‡ï¼ˆ`--target-update-freq 2000`ï¼‰
- è°ƒæ•´å¥–åŠ±å‡½æ•°å‚æ•°
- å¢åŠ è®­ç»ƒè½®æ•°

### Q3: å†…å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ

**è§£å†³æ–¹æ¡ˆï¼š**
- å‡å°‘ `memory_size`ï¼ˆ`--memory-size 50000`ï¼‰
- å‡å°‘ `batch_size`ï¼ˆ`--batch-size 32`ï¼‰

### Q4: å¦‚ä½•ä¸­æ–­è®­ç»ƒï¼Ÿ

**æŒ‰ `Ctrl+C`**ï¼Œæ¨¡å‹ä¼šè‡ªåŠ¨ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„ã€‚

### Q5: è®­ç»ƒå¥½çš„æ¨¡å‹åœ¨å“ªé‡Œï¼Ÿ

æ¨¡å‹ä¿å­˜åœ¨å½“å‰ç›®å½•ä¸‹çš„ `dqn_2048_model.pth`ï¼ˆæˆ–ä½ æŒ‡å®šçš„è·¯å¾„ï¼‰ã€‚

---

## ğŸ® ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹

### åœ¨æ¸¸æˆä¸­åŠ è½½

1. è¿è¡Œæ¸¸æˆï¼š`python puzzle.py`
2. é€‰æ‹© AI Type ä¸º "DQN"
3. Agent ä¼šè‡ªåŠ¨åŠ è½½ `dqn_2048_model.pth`ï¼ˆå¦‚æœå­˜åœ¨ï¼‰

### æ‰‹åŠ¨åŠ è½½

```python
from agent_Qlearning import DQNAgent

agent = DQNAgent(special_pos=(1, 1))
agent.load("dqn_2048_model.pth")

# ä½¿ç”¨ agent
move = agent.choose_move(game_matrix)
```

---

## ğŸ“ è®­ç»ƒæ—¥å¿—ç¤ºä¾‹

```
============================================================
DQN Agent Training for 2048 Game
============================================================
Special tile position: Auto-detect enabled

Creating DQN Agent...
Starting training from scratch...

Training parameters:
  Episodes: 10000
  Save frequency: 1000
  Save path: dqn_2048_model.pth
  Learning rate: 0.001
  Gamma: 0.99
  Batch size: 64
  Device: cuda
============================================================
Episode 100/10000 | Avg Reward: -1234.56 | Avg Length: 45.23 | Epsilon: 0.951
Episode 200/10000 | Avg Reward: -987.65 | Avg Length: 52.34 | Epsilon: 0.904
...
Episode 10000/10000 | Avg Reward: 1234.56 | Avg Length: 234.56 | Epsilon: 0.010
============================================================
Training completed successfully!
Final model saved to: dqn_2048_model.pth
Average reward (last 100 episodes): 1234.56
Average length (last 100 episodes): 234.56
============================================================
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹å‘½ä»¤

```bash
# æœ€ç®€å•çš„è®­ç»ƒï¼ˆä½¿ç”¨é»˜è®¤å‚æ•°ï¼‰
python train_dqn.py

# å¿«é€Ÿæµ‹è¯•ï¼ˆ1000 episodesï¼‰
python train_dqn.py --episodes 1000

# å®Œæ•´è®­ç»ƒï¼ˆ20000 episodesï¼‰
python train_dqn.py --episodes 20000 --save-freq 2000
```

---

## ğŸ“š æ›´å¤šä¿¡æ¯

- æŸ¥çœ‹ `DQN_README.md` äº†è§£ DQN agent çš„è¯¦ç»†è¯´æ˜
- æŸ¥çœ‹ `agent_Qlearning.py` äº†è§£å®ç°ç»†èŠ‚
- åœ¨æ¸¸æˆä¸­æµ‹è¯•è®­ç»ƒå¥½çš„æ¨¡å‹





