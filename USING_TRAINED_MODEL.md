# ä½¿ç”¨è®­ç»ƒå¥½çš„ DQN Agent æŒ‡å—

## âœ… å¥½æ¶ˆæ¯ï¼šä½ çš„æ¨¡å‹å·²ç»å‡†å¤‡å¥½äº†ï¼

æˆ‘çœ‹åˆ°ä½ å·²ç»æœ‰äº†è®­ç»ƒå¥½çš„æ¨¡å‹æ–‡ä»¶ï¼š`dqn_2048_model.pth`

## ğŸ® æ–¹æ³• 1ï¼šåœ¨æ¸¸æˆä¸­ç›´æ¥ä½¿ç”¨ï¼ˆæœ€ç®€å•ï¼‰

### æ­¥éª¤ï¼š

1. **è¿è¡Œæ¸¸æˆï¼š**
   ```bash
   python puzzle.py
   ```

2. **åœ¨æ¸¸æˆç•Œé¢ä¸­ï¼š**
   - ç‚¹å‡» **"AI"** å•é€‰æŒ‰é’®ï¼ˆåˆ‡æ¢åˆ° AI æ¨¡å¼ï¼‰
   - ç‚¹å‡» **"DQN"** å•é€‰æŒ‰é’®ï¼ˆé€‰æ‹© DQN agentï¼‰
   - å‹¾é€‰ **"Auto-play"**ï¼ˆè‡ªåŠ¨æ¸¸æˆï¼‰

3. **æ¨¡å‹ä¼šè‡ªåŠ¨åŠ è½½ï¼**

   æ¸¸æˆå¯åŠ¨æ—¶ï¼Œå¦‚æœæ£€æµ‹åˆ° `dqn_2048_model.pth` æ–‡ä»¶ï¼Œä¼šè‡ªåŠ¨åŠ è½½å¹¶æ˜¾ç¤ºï¼š
   ```
   Loaded DQN model from dqn_2048_model.pth
   ```

4. **å¼€å§‹æ¸¸æˆï¼š**
   - Agent ä¼šè‡ªåŠ¨å¼€å§‹æ¸¸æˆ
   - æˆ–è€…æŒ‰ **Space** é”®å•æ­¥æ‰§è¡Œ

### é”®ç›˜å¿«æ·é”®ï¼š

- **`m`** - åˆ‡æ¢ Human/AI æ¨¡å¼
- **`t`** - åˆ‡æ¢ AI ç±»å‹ï¼ˆMinimax/Expectimax/DQNï¼‰
- **`Space`** - AI å•æ­¥æ‰§è¡Œï¼ˆå½“ Auto-play å…³é—­æ—¶ï¼‰
- **`r`** - é‡æ–°å¼€å§‹æ¸¸æˆ

---

## ğŸ æ–¹æ³• 2ï¼šåœ¨ Python ä»£ç ä¸­ä½¿ç”¨

### åŸºæœ¬ä½¿ç”¨ï¼š

```python
from agent_Qlearning import DQNAgent
import logic

# åˆ›å»º agent
agent = DQNAgent(
    special_pos=None,  # æˆ–æŒ‡å®šä½ç½®ï¼Œå¦‚ (1, 1)
    auto_detect_special=True
)

# åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
agent.load("dqn_2048_model.pth")

# è·å–å½“å‰æ¸¸æˆçŠ¶æ€
game_matrix = logic.new_game(4)  # 4x4 æ£‹ç›˜

# è®© agent é€‰æ‹©ç§»åŠ¨
move = agent.choose_move(game_matrix)
print(f"Agent chose: {move}")  # è¾“å‡º: Up, Down, Left, æˆ– Right
```

### å®Œæ•´æ¸¸æˆå¾ªç¯ç¤ºä¾‹ï¼š

```python
from agent_Qlearning import DQNAgent
import logic
import constants as c

# åˆ›å»ºå¹¶åŠ è½½ agent
agent = DQNAgent(special_pos=None, auto_detect_special=True)
agent.load("dqn_2048_model.pth")

# åˆå§‹åŒ–æ¸¸æˆ
matrix = logic.new_game(c.GRID_LEN)
steps = 0

# æ¸¸æˆå¾ªç¯
while logic.game_state(matrix) == "not over":
    # Agent é€‰æ‹©ç§»åŠ¨
    move = agent.choose_move(matrix)
    
    if move is None:
        print("No valid moves!")
        break
    
    # æ‰§è¡Œç§»åŠ¨
    if move == "Up":
        matrix, _ = logic.up(matrix)
    elif move == "Down":
        matrix, _ = logic.down(matrix)
    elif move == "Left":
        matrix, _ = logic.left(matrix)
    elif move == "Right":
        matrix, _ = logic.right(matrix)
    
    # åº”ç”¨ç‰¹æ®Šæ ¼æ•ˆæœï¼ˆå¦‚æœéœ€è¦ï¼‰
    # ... ä½ çš„ç‰¹æ®Šæ ¼é€»è¾‘ ...
    
    # æ·»åŠ æ–° tile
    matrix = logic.add_two(matrix)
    
    steps += 1
    print(f"Step {steps}: {move}")

print(f"Game over after {steps} steps")
```

---

## ğŸ” éªŒè¯æ¨¡å‹æ˜¯å¦åŠ è½½æˆåŠŸ

### åœ¨æ¸¸æˆä¸­éªŒè¯ï¼š

1. è¿è¡Œæ¸¸æˆï¼š`python puzzle.py`
2. é€‰æ‹© DQN agent
3. æŸ¥çœ‹æ§åˆ¶å°è¾“å‡ºï¼Œåº”è¯¥çœ‹åˆ°ï¼š
   ```
   Loaded DQN model from dqn_2048_model.pth
   ```

### åœ¨ä»£ç ä¸­éªŒè¯ï¼š

```python
from agent_Qlearning import DQNAgent

agent = DQNAgent()
try:
    agent.load("dqn_2048_model.pth")
    print("âœ… Model loaded successfully!")
    print(f"Current epsilon: {agent.epsilon}")  # åº”è¯¥æ¥è¿‘ 0.01ï¼ˆè®­ç»ƒç»“æŸæ—¶çš„å€¼ï¼‰
except Exception as e:
    print(f"âŒ Failed to load model: {e}")
```

---

## ğŸ“Š æµ‹è¯•æ¨¡å‹æ€§èƒ½

### åœ¨æ¸¸æˆä¸­æµ‹è¯•ï¼š

1. è¿è¡Œæ¸¸æˆå¹¶é€‰æ‹© DQN agent
2. è§‚å¯Ÿ agent çš„è¡¨ç°ï¼š
   - æ˜¯å¦èƒ½è¾¾åˆ°è¾ƒé«˜çš„åˆ†æ•°ï¼Ÿ
   - æ˜¯å¦èƒ½é¿å…ç‰¹æ®Šæ ¼ï¼Ÿ
   - æ¸¸æˆé•¿åº¦å¦‚ä½•ï¼Ÿ

### æ‰¹é‡æµ‹è¯•ï¼ˆä»£ç ï¼‰ï¼š

```python
from agent_Qlearning import DQNAgent
import logic
import constants as c

agent = DQNAgent(special_pos=None, auto_detect_special=True)
agent.load("dqn_2048_model.pth")

# æµ‹è¯•å¤šå±€æ¸¸æˆ
num_games = 10
results = []

for game in range(num_games):
    matrix = logic.new_game(c.GRID_LEN)
    steps = 0
    max_tile = 0
    
    while logic.game_state(matrix) == "not over":
        move = agent.choose_move(matrix)
        if move is None:
            break
        
        # æ‰§è¡Œç§»åŠ¨ï¼ˆç®€åŒ–ç‰ˆï¼‰
        if move == "Up":
            matrix, _ = logic.up(matrix)
        elif move == "Down":
            matrix, _ = logic.down(matrix)
        elif move == "Left":
            matrix, _ = logic.left(matrix)
        elif move == "Right":
            matrix, _ = logic.right(matrix)
        
        matrix = logic.add_two(matrix)
        steps += 1
        max_tile = max(max(row) for row in matrix)
    
    results.append({
        'steps': steps,
        'max_tile': max_tile,
        'state': logic.game_state(matrix)
    })
    print(f"Game {game+1}: {steps} steps, max tile: {max_tile}")

# ç»Ÿè®¡ç»“æœ
avg_steps = sum(r['steps'] for r in results) / len(results)
avg_max_tile = sum(r['max_tile'] for r in results) / len(results)
print(f"\nAverage: {avg_steps:.1f} steps, {avg_max_tile:.1f} max tile")
```

---

## âš™ï¸ ä½¿ç”¨ä¸åŒåç§°çš„æ¨¡å‹æ–‡ä»¶

å¦‚æœä½ çš„æ¨¡å‹æ–‡ä»¶åä¸æ˜¯ `dqn_2048_model.pth`ï¼Œæœ‰ä¸¤ç§æ–¹æ³•ï¼š

### æ–¹æ³• 1ï¼šé‡å‘½åæ–‡ä»¶

```bash
# å°†ä½ çš„æ¨¡å‹æ–‡ä»¶é‡å‘½åä¸ºé»˜è®¤åç§°
mv your_model.pth dqn_2048_model.pth
```

### æ–¹æ³• 2ï¼šä¿®æ”¹ä»£ç ï¼ˆä¸´æ—¶ï¼‰

åœ¨ `puzzle.py` ä¸­ä¿®æ”¹æ¨¡å‹è·¯å¾„ï¼ˆç¬¬ 128 è¡Œï¼‰ï¼š

```python
model_path = "your_model.pth"  # æ”¹ä¸ºä½ çš„æ–‡ä»¶å
```

### æ–¹æ³• 3ï¼šåœ¨ä»£ç ä¸­æ‰‹åŠ¨åŠ è½½

```python
from agent_Qlearning import DQNAgent

agent = DQNAgent()
agent.load("your_model.pth")  # ä½¿ç”¨ä½ çš„æ¨¡å‹æ–‡ä»¶å
```

---

## ğŸ¯ æœ€ä½³å®è·µ

### 1. ç¡®ä¿æ¨¡å‹æ–‡ä»¶åœ¨æ­£ç¡®ä½ç½®

æ¨¡å‹æ–‡ä»¶ `dqn_2048_model.pth` åº”è¯¥å’Œ `puzzle.py` åœ¨åŒä¸€ç›®å½•ä¸‹ã€‚

### 2. æ£€æŸ¥æ¨¡å‹æ˜¯å¦è®­ç»ƒå……åˆ†

- è®­ç»ƒ 500 æ¬¡ï¼šå¯èƒ½æ€§èƒ½ä¸€èˆ¬ï¼Œé€‚åˆæµ‹è¯•
- è®­ç»ƒ 10000+ æ¬¡ï¼šæ€§èƒ½æ›´å¥½ï¼Œé€‚åˆå®é™…ä½¿ç”¨

### 3. è§‚å¯Ÿ agent è¡Œä¸º

- **å¥½çš„è¡¨ç°**ï¼šèƒ½æŒç»­æ¸¸æˆï¼Œé¿å…ç‰¹æ®Šæ ¼ï¼Œè¾¾åˆ°è¾ƒé«˜åˆ†æ•°
- **éœ€è¦æ”¹è¿›**ï¼šé¢‘ç¹å¤±è´¥ï¼Œæ— æ³•é¿å…ç‰¹æ®Šæ ¼ï¼Œåˆ†æ•°è¾ƒä½

### 4. ç»§ç»­è®­ç»ƒï¼ˆå¦‚æœéœ€è¦ï¼‰

å¦‚æœæ¨¡å‹æ€§èƒ½ä¸å¤Ÿå¥½ï¼Œå¯ä»¥ç»§ç»­è®­ç»ƒï¼š

```bash
# ä»ç°æœ‰æ¨¡å‹ç»§ç»­è®­ç»ƒ
python train_dqn.py \
    --load-path dqn_2048_model.pth \
    --episodes 5000 \
    --save-path dqn_2048_model_v2.pth
```

---

## ğŸ› å¸¸è§é—®é¢˜

### Q1: æ¨¡å‹åŠ è½½å¤±è´¥ï¼Ÿ

**æ£€æŸ¥ï¼š**
- æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Ÿ
- æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼Ÿ
- PyTorch ç‰ˆæœ¬æ˜¯å¦å…¼å®¹ï¼Ÿ

**è§£å†³æ–¹æ¡ˆï¼š**
```python
import torch
print(torch.__version__)  # æ£€æŸ¥ PyTorch ç‰ˆæœ¬
```

### Q2: Agent è¡¨ç°å¾ˆå·®ï¼Ÿ

**å¯èƒ½åŸå› ï¼š**
- è®­ç»ƒæ¬¡æ•°å¤ªå°‘ï¼ˆ500 æ¬¡å¯èƒ½ä¸å¤Ÿï¼‰
- æ¨¡å‹æ–‡ä»¶æŸå
- ç‰¹æ®Šæ ¼ä½ç½®ä¸åŒ¹é…

**è§£å†³æ–¹æ¡ˆï¼š**
- ç»§ç»­è®­ç»ƒæ›´å¤š episodes
- é‡æ–°è®­ç»ƒæ¨¡å‹
- æ£€æŸ¥ç‰¹æ®Šæ ¼ä½ç½®è®¾ç½®

### Q3: å¦‚ä½•çŸ¥é“æ¨¡å‹æ˜¯å¦åœ¨è¿è¡Œï¼Ÿ

**æ£€æŸ¥æ–¹æ³•ï¼š**
- æŸ¥çœ‹æ§åˆ¶å°è¾“å‡ºï¼ˆåº”è¯¥æ˜¾ç¤º "Loaded DQN model..."ï¼‰
- è§‚å¯Ÿæ¸¸æˆä¸­çš„ç§»åŠ¨ï¼ˆåº”è¯¥æ˜¯æœ‰ç­–ç•¥çš„ï¼Œä¸æ˜¯å®Œå…¨éšæœºï¼‰
- æ£€æŸ¥ agent çš„ epsilon å€¼ï¼ˆåº”è¯¥æ¥è¿‘ 0.01ï¼‰

---

## ğŸ“ å¿«é€Ÿå¼€å§‹æ¸…å•

- [ ] ç¡®è®¤ `dqn_2048_model.pth` æ–‡ä»¶å­˜åœ¨
- [ ] è¿è¡Œ `python puzzle.py`
- [ ] é€‰æ‹© "AI" æ¨¡å¼
- [ ] é€‰æ‹© "DQN" agent
- [ ] å‹¾é€‰ "Auto-play"
- [ ] è§‚å¯Ÿ agent è¡¨ç°

---

## ğŸ‰ æ€»ç»“

**æœ€ç®€å•çš„ä½¿ç”¨æ–¹æ³•ï¼š**

1. è¿è¡Œæ¸¸æˆï¼š`python puzzle.py`
2. é€‰æ‹© DQN agent
3. å¼€å§‹æ¸¸æˆï¼

æ¨¡å‹ä¼šè‡ªåŠ¨åŠ è½½ï¼Œæ— éœ€é¢å¤–é…ç½®ï¼ğŸš€



